{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "azdias = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_AZDIAS_052018.csv', sep=';')\n",
    "customers = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_CUSTOMERS_052018.csv', sep=';')\n",
    "\n",
    "#import os\n",
    "#os.getcwd()\n",
    "#azdias.to_csv('/home/workspace/Udacity_AZDIAS_052018.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below defines a function to treat the not available (NA) cells or missing values:\n",
    "    - remove features with more than 20% of NA, this can also be done with dropna method\n",
    "    - drop records with not available data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Treating NA in pandas dataframe ---\n",
      "Shape of dataframe after NA treatment:  (191652, 369)\n",
      "Shape of dataframe before NA treatment:  (185560, 113)\n",
      "\n",
      "Number of features removed:  256\n",
      "Percentage of records removed:  3.18 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def treat_NA(df, por_nas):\n",
    "    \"\"\"\n",
    "    Remove features with por_nas % of NA and drop records with NA\n",
    "    \n",
    "    Input:\n",
    "        df: pandas dataframe\n",
    "        por_nas: maximun porcentage of NA that a feature must have to be romoved\n",
    "        \n",
    "    Output:\n",
    "        df_new: pandas dataframe without NA\n",
    "    \"\"\"\n",
    "    \n",
    "    por_nas_cols = df.isna().sum(axis = 0) / df.shape[0] * 100\n",
    "    new_cols = df.columns[por_nas_cols < por_nas] \n",
    "    try:\n",
    "        new_cols = new_cols.drop(['CUSTOMER_GROUP', 'ONLINE_PURCHASE', 'PRODUCT_GROUP'])\n",
    "    except:\n",
    "        pass\n",
    "    df_nas = df[list(new_cols)]\n",
    "    df_nas.dropna(inplace=True)\n",
    "    \n",
    "    # Unknown classes treatment\n",
    "    #por_nas_cols = np.sum(c_nas.iloc[:,:] == -1, axis = 0) / c_nas.shape[0] * 100\n",
    "    #new_cols = c_nas.columns[por_nas_cols > 20] \n",
    "    \n",
    "    print('--- Treating NA in pandas dataframe ---')\n",
    "    print('Shape of dataframe after NA treatment: ', df.shape)\n",
    "    print('Shape of dataframe before NA treatment: ', df_nas.shape)\n",
    "    print('\\nNumber of features removed: ', df.shape[1]-df_nas.shape[1])\n",
    "    print('Percentage of records removed: ', round((df.shape[0]-df_nas.shape[0])/df.shape[0]*100, 2), '%')\n",
    "    \n",
    "    return df_nas\n",
    "\n",
    "c_nas = treat_NA(customers, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below defines a function that first transforms categorical variables into dummies and second standardize the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating dummies and standardizing ---\n",
      "Number of dummies variables created:  0\n",
      "Number of scaled features:  113\n"
     ]
    }
   ],
   "source": [
    "def dummies_and_scale(df_nas):\n",
    "    \"\"\"\n",
    "    Transform categorical features and standardize numerical ones\n",
    "    \n",
    "    Input:\n",
    "        df_nas: dataframe without NA\n",
    "        \n",
    "    Output:\n",
    "        df_dummies: dataframe without categorical features \n",
    "        df_scaled: dataframe without categorical features and standardize \n",
    "    \"\"\"\n",
    "    \n",
    "    df_dummies = pd.get_dummies(df_nas) \n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df_dummies.astype(float)))\n",
    "    df_scaled.columns = df_dummies.columns\n",
    "    df_scaled.index = df_dummies.index\n",
    "\n",
    "    print('--- Creating dummies and standardizing ---')\n",
    "    print('Number of dummies variables created: ', df_dummies.shape[1]-df_nas.shape[1])\n",
    "    print('Number of scaled features: ', df_scaled.shape[1])\n",
    "    return df_dummies, df_scaled\n",
    "\n",
    "c_dummies, c_scaled = dummies_and_scale(c_nas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cells are related to feature selection, which is an important step before doing exploratory analysis or any other. The different methods that I propose are explianed in the report.pdf. I propose three methods:\n",
    "    - Principal component analysis (PCA)\n",
    "    - Sparse PCA\n",
    "    - Logistic regression\n",
    "    \n",
    "So, the first thing before finding the most representative features of the dataset is implementing functions for PCA, SparsePCA and logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating PCAs ---\n",
      "Number of principal components created:  25\n",
      "Porcentage of the total variance explained:  0.77 %\n",
      "--- Creating PCAs ---\n",
      "Number of principal components created:  3\n",
      "Porcentage of the total variance explained:  0.46 %\n"
     ]
    }
   ],
   "source": [
    "def PCA_decomposition(df_scaled, n_pca, method):\n",
    "    \"\"\"\n",
    "    This function creates n_pca number of principal components of a given dataset.\n",
    "    \n",
    "    Input:\n",
    "        df_cleaned: dataframe without categorical features and standardize \n",
    "        n_pca: number of components\n",
    "        method: 'PCA' or 'SparsePCA'\n",
    "        \n",
    "    Output:\n",
    "        loadings: the transformation matrix from dr_cleaned to the new variables\n",
    "        df_pcas: the new dataframe   \n",
    "    \"\"\"\n",
    "    \n",
    "    pca = PCA(n_components = n_pca)\n",
    "    pca.fit(df_scaled)\n",
    "    por_exp = round(np.sum(pca.explained_variance_ratio_), 2)\n",
    "    \n",
    "    if method == 'SparsePCA':\n",
    "        pca = SparsePCA(n_components = n_pca)\n",
    "        pca.fit(df_scaled)\n",
    "        \n",
    "    loadings = pca.components_\n",
    "    df_pcas = pd.DataFrame(np.matmul(df_scaled, np.transpose(pca.components_)))\n",
    "    \n",
    "    print('--- Creating PCAs ---')\n",
    "    print('Number of principal components created: ', n_pca)\n",
    "    print('Porcentage of the total variance explained: ', por_exp, '%')\n",
    "    return loadings, df_pcas\n",
    "\n",
    "c_loading, c_df_pcas = PCA_decomposition(c_scaled, 25, 'PCA')\n",
    "c_loadingS, c_df_Spcas = PCA_decomposition(c_scaled, 3, 'SparsePCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_reg(y, X):\n",
    "    \"\"\"\n",
    "    Fit a logistic model.\n",
    "    \n",
    "    Input:\n",
    "        y: response variable\n",
    "        X: explanatory variables\n",
    "        \n",
    "    Output: estimation parameters\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    clf = LogisticRegression().fit(X, y)\n",
    "    return clf, clf.coef_\n",
    "    \n",
    "y = customers['ONLINE_PURCHASE'][list(c_scaled.index)]\n",
    "X = c_scaled\n",
    "c_clf, c_coefs = logit_reg(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(sort_dict, features, n_importance):\n",
    "    \"\"\"\n",
    "    Given the importance of each feature this function returns the n_importance number of them\n",
    "    \n",
    "    Input:\n",
    "        sort_dict: dictionary containing the importance of each feature\n",
    "        features: list of features\n",
    "        n_imoprtance: number of features to be choosen\n",
    "        \n",
    "    Output: return the most important features\n",
    "    \"\"\"\n",
    "    \n",
    "    aux = dict(enumerate(abs(sort_dict[0])))\n",
    "    aux_sort = {k: v for k, v in sorted(aux.items(), key=lambda item: item[1])}    \n",
    "    cols = features[list(aux_sort.keys())[-n_importance:]]\n",
    "    print(list(reversed(cols.tolist())))\n",
    "    return list(reversed(cols.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FINANZ_ANLEGER', 'D19_KONSUMTYP_MAX', 'VERS_TYP', 'FINANZ_UNAUFFAELLIGER', 'SEMIO_VERT']\n",
      "['D19_BANKEN_DATUM', 'D19_BANKEN_ONLINE_DATUM', 'D19_BANKEN_OFFLINE_DATUM', 'D19_VERSAND_ONLINE_DATUM', 'D19_TELKO_OFFLINE_DATUM']\n",
      "['CJT_TYP_4', 'CJT_TYP_3', 'CJT_TYP_1', 'CJT_KATALOGNUTZER', 'CJT_TYP_6']\n"
     ]
    }
   ],
   "source": [
    "cols_pca = select_features(c_loading, c_scaled.columns, 5) # [69, 37, 109, 73, 107] \n",
    "cols_spca = select_features(c_loadingS, c_scaled.columns, 5)  # [12, 17, 16, 59, 51]\n",
    "cols_logit = select_features(c_coefs, c_scaled.columns, 5) # [90, 95, 59, 7, 74]\n",
    "selected_cols = np.unique(cols_pca + cols_spca + cols_logit).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have found the most relevant features of the customers dataset, an exploratory analysis can be done. For example, correlation between the selected features is a good start, since high correlated features must be removed. also, a percentage of correlation per feature is displayed as a resume of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALTERSKATEGORIE_GROB        42.558171\n",
       "D19_BANKEN_DATUM            34.691026\n",
       "D19_BANKEN_OFFLINE_DATUM    22.495457\n",
       "D19_BANKEN_ONLINE_DATUM     26.836234\n",
       "D19_GESAMT_ANZ_12           42.351565\n",
       "D19_KONSUMTYP_MAX           53.777987\n",
       "D19_TELKO_OFFLINE_DATUM     23.460476\n",
       "D19_VERSAND_ONLINE_DATUM    40.358096\n",
       "FINANZ_ANLEGER              49.215798\n",
       "FINANZ_UNAUFFAELLIGER       48.790627\n",
       "KOMBIALTER                  56.616979\n",
       "PRAEGENDE_JUGENDJAHRE       42.302381\n",
       "SEMIO_VERT                  48.402437\n",
       "VERS_TYP                    53.359115\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_cleaned_s = c_dummies[selected_cols]\n",
    "cors = c_cleaned_s.corr()\n",
    "abs(cors)\n",
    "abs(cors).sum(axis=1) / cors.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell creates histograms for every selected feature, from ind = 0 to ind = 13 (14 features). It also prints unique values per feature. Finally, a descriptive statistics summary is depicted for those customers that purchase online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in KOMBIALTER are: [1 2 3 4 9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc09c7714a8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 10\n",
    "uniques_col = np.unique(c_cleaned_s.iloc[:,ind]) \n",
    "print('Unique values in', selected_cols[ind], 'are:', uniques_col)\n",
    "plt.hist(c_cleaned_s.iloc[:,ind], bins='auto')\n",
    "plt.title('Histogram of ' + selected_cols[ind] + ' feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.552274636898328"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y.sum() / y.shape[0] * 100\n",
    "c_cleaned_s_1 = c_cleaned_s[y == 1]\n",
    "c_cleaned_s_1.describe().round().iloc[:,:5]\n",
    "y[c_cleaned_s.iloc[:,ind] == 4].sum() / y.sum()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploratory analysis is done clustering for the customers dataset is the next step. First, we must choose a good numbre of clusters, k. That is, finding a good trade off between inertia (sum of errors per cluster) and k. For this purpose, the graph below is very useful. A good k is when erros stops decreasing. In this case, k = 30 would be a good option in term of error but not in terms of efficiency computing or interpretability, so k = 5 is choosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8nGW5//HPlaRpmrVN06bpku6UlJY1lLLIIsimLKKooLIqiqgov6OixyOIG+ByFDigyH7YD2sFSqnILltalq5AC93TvU3Tpmm26/fHc6cdSpZJm+kkk+/79ZrXzNzzLNfjSL597uee+zF3R0REJJHSkl2AiIikPoWNiIgknMJGREQSTmEjIiIJp7AREZGEU9iIiEjCKWxEdpOZXWlmd+/hfW42s1EJ2O4ePxbpGRQ2InEws7PNrCL8ka80s6lmdkSy6nH3XHf/MFn7F+kohY1IO8zsMuDPwG+BYqAUuBE4LZl1iXQnChuRNphZAXAVcIm7P+LuW9y93t3/4e4/ilk008zuMrNqM5tjZuUx2ygzs+fNbGP47NTY7Yf11pjZYjP7uZmlhc/GmNkLZlZlZmvN7IGY9dzMxoTXd5jZ/5jZk2H/r5vZ6Jhljzez98J2bgzb/EYcx97LzO4zs4fNLHO3/oeUHk9hI9K2Q4Es4NF2ljsVuB/oC0wBboDoDzbwD+AZYCDwPeAeMxsX1rseKABGAUcB5wDnh89+FdbrBwwNy7bmLOCXYdkFwG/C/ouAh4CfAv2B94DD2jtoM+sDPAZsA77k7nXtrSPSFoWNSNv6A2vdvaGd5V5296fcvRH4X2C/0D4ZyAWudvc6d/8X8ARwlpmlA18Gfuru1e6+CPgj8PWwbj0wHBjs7rXu/nIb+3/E3d8Idd4D7B/aTwbmhLOyBuA6YGU7x5IPPA0sBM4PxySyWxQ2Im1bBxSZWUY7y8X+Aa8BssI6g4Gl7t4U8/liYAhQBGSG9zt/BvBjwIA3QvfbBR3Yf254PRhY2vyBRzPvLmvnWCYD+xIFpGbqlU6hsBFp26tALXD6Lq6/AhjWfB0mKAWWA2vZcfay82e4+0p3/6a7Dwa+BdzYfJ2mAyqJuuAAMDOLfd+KZ4DfAc+aWXEH9yfSIoWNSBvcvQr4BfA/Zna6mWWHC+cnmdm1cWzidWAL8OOw3tHAKcD9oXvqQeA3ZpZnZsOBy4C7AczsTDNrDoYNgAMd7dJ6EpgYas8ALgEGtbeSu18L3EsUOEUd3KfIJyhsRNrh7n8iCoGfA2uIuqW+S3QBvb1164gGD5xEdCZzI3COu88Pi3yPKIw+BF4m+gN/W/jsYOB1M9tMNOjgUnf/qIO1rwXOBK4l6hIcD1QQXfhvb91fER3jP82ssCP7FdmZqUtWpOcI3XnLgK+6+3PJrkd6Dp3ZiKQ4MzvBzPqaWW/gZ0SDDl5LclnSwyhsRFLfoUTDmNcSXS863d23Jrck6WnUjSYiIgmnMxsREUm49n6o1mMUFRX5iBEjkl2GiEi3MmPGjLXuPqC95RQ2wYgRI6ioqEh2GSIi3YqZLW5/KXWjiYjIHqCwERGRhFPYiIhIwilsREQk4RQ2IiKScAobERFJOIWNiIgknMJmNz3+9nLufi2uYeYiIj2WwmY3TZ21kltf7tAtRkREehyFzW4qK8ln0botbNnWkOxSRES6LIXNbiorycMd5q+sTnYpIiJdlsJmN5WV5AMwr3JTkisREem6FDa7aWi/PuRlZShsRETaoLDZTWZGWUm+wkZEpA0JDRszu9TMZpvZHDP7QWgrNLPpZvZBeO4X2s3MrjOzBWb2rpkdGLOdc8PyH5jZuTHtB5nZrLDOdWZmbe0jUcaX5DN/ZTVNTbrrqYhISxIWNmY2AfgmMAnYD/icmY0FLgeedfexwLPhPcBJwNjwuAi4KWynELgCOCRs64qY8LgpLNu83omhvbV9JERZSR41dY0sXl+TyN2IiHRbiTyzKQNec/cad28AXgA+D5wG3BmWuRM4Pbw+DbjLI68Bfc2sBDgBmO7u6919AzAdODF8lu/ur7q7A3fttK2W9pGYA9UgARGRNiUybGYDR5pZfzPLBk4GhgHF7l4JEJ4HhuWHAEtj1l8W2tpqX9ZCO23s42PM7CIzqzCzijVr1uzyge5VnEd6milsRERakbCwcfd5wDVEZyJPA+8Abf3y0VrazC60d6TGm9293N3LBwxo9xbarcrqlc6oohyFjYhIKxI6QMDdb3X3A939SGA98AGwKnSBEZ5Xh8WXEZ35NBsKrGinfWgL7bSxj4QpK8ln7gqFjYhISxI9Gm1geC4FzgDuA6YAzSPKzgUeD6+nAOeEUWmTgarQBTYNON7M+oWBAccD08Jn1WY2OYxCO2enbbW0j4QpK8lnRVUtG2vqEr0rEZFuJyPB23/YzPoD9cAl7r7BzK4GHjSzC4ElwJlh2aeIrussAGqA8wHcfb2Z/Qp4Myx3lbuvD68vBu4A+gBTwwOgtX0kzPjBzYMEqjl0dP9E705EpFtJaNi4+6daaFsHHNtCuwOXtLKd24DbWmivACbEu49EKivJA6IRaQobEZGP0wwCnWRgXhZFuZkaJCAi0gKFTScqK8lnrsJGROQTFDadqKwknw9Wbaa+sSnZpYiIdCkKm040viSfusYmPlyzJdmliIh0KQqbTqRpa0REWqaw6USjBuSQmZ6m6zYiIjtR2HSiXulpjC3O1ZmNiMhOFDadbLxupCYi8gkKm05WVpLP2s11rK6uTXYpIiJdhsKmk+0YJFCd5EpERLoOhU0nGx/CRjNAi4jsoLDpZAXZvRhckKXrNiIiMRQ2CTB+sAYJiIjEUtgkQFlJPh+u3UJtfWOySxER6RIUNglQVpJPY5Pz/ioNEhARAYVNQmjaGhGRj1PYJMDwwmyyM9M1/FlEJFDYJEBamrH3oDzNkSYiEihsEqQsTFsT3e1aRKRnU9gkSFlJPtW1DSzbsDXZpYiIJJ3CJkE0SEBEZAeFTYLsPSgPM82RJiICCpuEyemdwYj+OTqzERFBYZNQZSV5zFupsBERaTNszCzdzO7eU8WkmrJB+SxeV0N1bX2ySxERSao2w8bdG4EBZpa5h+pJKeMHR4ME3lup6zYi0rNlxLHMIuAVM5sCbGludPc/JaqoVBE7Iq18RGGSqxERSZ54wmZFeKQBeYktJ7WUFGRR0KcXczUiTUR6uHbDxt1/CWBmOe6+pb3lZQczo6xE09aIiLQ7Gs3MDjWzucC88H4/M7sx4ZWliPElBby3chONTZq2RkR6rniGPv8ZOAFYB+Du7wBHJrKoVFJWkkdtfROL1umkUER6rrh+Z+PuS3dq0i0o46Rpa0RE4gubpWZ2GOBmlmlm/0HoUpP2jS3OJSPNFDYi0qPFEzbfBi4BhgDLgP2B7ySyqFTSOyOd0QNymbtCYSMiPVc8Q5/HuftXYxvM7HDglcSUlHrGD87n1YXrkl2GiEjSxHNmc32cbdKKspI8Vm6qZcOWumSXIiKSFK2GTRjy/P+Ipqu5LOZxJZAez8bN7IdmNsfMZpvZfWaWZWYjzex1M/vAzB5ongrHzHqH9wvC5yNitvPT0P6emZ0Q035iaFtgZpfHtLe4j2TRIAER6enaOrPJBHKJutryYh6bgC+2t2EzGwJ8Hyh39wlEAfUV4Brgv919LLABuDCsciGwwd3HAP8dlsPMxof19gFOBG4ME4SmA/8DnASMB84Ky9LGPpKiOWz0404R6alavWbj7i8AL5jZHe6+GMDM0oBcd4/3r2YG0MfM6oFsoBL4NHB2+PxO4ErgJuC08BrgIeAGM7PQfr+7bwM+MrMFwKSw3AJ3/zDUdj9wmpnNa2MfSVGU25uBeb0VNiLSY8VzzeZ3ZpZvZjnAXOA9M/tReyu5+3LgD8ASopCpAmYAG929ISy2jGiUG+F5aVi3ISzfP7Z9p3Vaa+/fxj4+xswuMrMKM6tYs2ZNe4e0W8pK8nXXThHpseIJm/HhTOZ04CmgFPh6eyuZWT+is5KRwGAgh6jLa2fN87hYK591VvsnG91vdvdydy8fMGBAS4t0mrKSfBasrqauoSmh+xER6YriCZteZtaLKGwed/d6WvnjvZPjgI/cfU1Y5xHgMKCvmTV33w0lmlEaojOQYQDh8wJgfWz7Tuu01r62jX0kTVlJHvWNzsI1m5NdiojIHhdP2PyN6J42OcCLZjacaJBAe5YAk80sO1x7OZaoG+45dgwwOBd4PLyeEt4TPv+Xu3to/0oYrTYSGAu8AbwJjA0jzzKJBhFMCeu0to+kGd88SEA/7hSRHiieWwxcB1wX07TYzI6JY73XzewhYCbQALwF3Aw8CdxvZr8ObbeGVW4F/jcMAFhPFB64+xwze5AoqBqAS8IdRDGz7wLTiEa63ebuc8K2ftLKPpJmZFEOvTPSNPxZRHoki04E2ljA7Bcttbv7VQmpKEnKy8u9oqIiofs49YaXycvK4J5vTE7ofkRE9hQzm+Hu5e0tF0832paYRyPRRf4Ru1VdD1U2KBqR1l7Ai4ikmni60f4Y+97M/kB0HUU6aN9hBTxQsZR5ldWMH5yf7HJERPaYuO5ns5NsYFRnF9ITfHZiCZkZadz/5pJklyIiskfFc1voWWb2bnjMAd4D/pL40lJP3+xMPjuxhEdnLqemrqH9FUREUkQ8txj4XMzrBmBVzK/zpYPOPqSUR99azhPvVvKl8mHtryAikgLamvW50MwKgeqYx1YgP7TLLigf3o8xA3O593V1pYlIz9HWmc0M2p7+RddtdoGZcfakUq56Yi5zV2zSQAER6RFaPbNx95HuPio87/xQ0OyGMw4cQmZGGve9obMbEekZ4hkg8HkzK4h539fMTk9sWamtb3Ymn5tYwmNvaaCAiPQM8Qx9vsLdq5rfuPtG4IrEldQznHVIKdXbGnjincpklyIiknDxhE1Ly8Qzik3asH2ggLrSRKQHiCdsKszsT2Y22sxGmdl/Ew0ekN3QPFDg7aUbNRO0iKS8eMLme0Ad8ADwINHw50sSWVRPoYECItJTxDM32hbg8j1QS48TO1DgpyfvTXameidFJDXtytxo0ok0UEBEegKFTZKVD+/H2IG53KOuNBFJYW2GjZmlm9kP91QxPZGZcdakUt5ZupE5K6raX0FEpBtqM2zC7ZdP20O19FhnHDiE3hooICIpLJ5utFfM7AYz+5SZHdj8SHhlPUjzrQcee2sFW7ZpRgERST3xDH86LDxfFdPmwKc7v5ye6+xDSnnkreU88e4KvnxwabLLERHpVPEMfT5mTxTS0x0UBgrc+/oShY2IpJx4JuIsNrNbzWxqeD/ezC5MfGk9i5lx9iGlvLOsitnLNVBARFJLPNds7gCmAYPD+/eBHySqoJ7s8wdooICIpKZ4wqbI3R8EmgDCLaEbE1pVD9U8UODxtzVQQERSSzxhs8XM+hMNCsDMJgPq50mQsw8pZfO2Bv7xzopklyIi0mniCZvLgCnAaDN7BbiLaHJOSYDmgQLqShORVNJu2Lj7TOAooiHQ3wL2cfd3E11YT6WBAiKSiuIZjZYFfB/4FfBL4JLQJglyxgFDNVBARFJKPN1odwH7ANcDNwDjgf9NZFE9XUF2Lz67rwYKiEjqiCdsxrn7he7+XHhcBOyV6MJ6uq+GgQK3v/JRsksREdlt8YTNW2EEGgBmdgjwSuJKEoCDhhfy2YklXPfsAhasrk52OSIiuyWesDkE+LeZLTKzRcCrwFFmNsvMNFAgga48dR+ye6fzo4fepbHJk12OiMgui2cizhMTXoW0aEBeb648ZR9+8MDb3PHvRVx4xMhklyQiskvimYhz8Z4oRFp22v6DmfLOCn4/bT7HlQ1keP+cZJckItJhui10F2dm/ObzE+iVlsblD8/CXd1pItL9KGy6gZKCPvzss2W8+uE67ntjabLLERHpsHh+1JljZmnh9V5mdqqZ9YpjvXFm9nbMY5OZ/cDMCs1supl9EJ77heXNzK4zswVm9m7s3UDN7Nyw/Admdm5M+0FhoMKCsK6F9hb30Z195eBhHDa6P799ah4rNm5NdjkiIh0Sz5nNi0CWmQ0BngXOJ7rtQJvc/T1339/d9wcOAmqAR4HLgWfdfWzY3uVhlZOAseFxEXATRMEBXEE0Km4ScEVMeNwUlm1er3kwQ2v76LbMjKvP2JfGJuc/H1V3moh0L/GEjbl7DXAGcL27f55oFoGOOBZYGAYbnAbcGdrvBE4Pr08D7vLIa0BfMysBTgCmu/t6d98ATAdODJ/lu/urHv3lvWunbbW0j26ttH82PzphHM+9t4bH3l6e7HJEROIWV9iY2aHAV4EnQ1s8Q6ZjfQW4L7wudvdKgPA8MLQPAWIvSCwLbW21L2uhva197HxgF5lZhZlVrFmzpoOHlBznHjaCA0v78st/zGVN9bZklyMiEpd4wuZS4KfAo+4+x8xGAc/FuwMzywROBf6vvUVbaPNdaI+bu9/s7uXuXj5gwICOrJo06WnGtV/cj5q6Rq6YMjvZ5YiIxKXNsDGzdOAUdz/V3a8BcPcP3f37HdjHScBMd18V3q8KXWCE59WhfRkwLGa9ocCKdtqHttDe1j5SwpiBuVx67FiemrWSqbMqk12OiEi72gwbd28kuri/O85iRxcaRDdiax5Rdi7weEz7OWFU2mSgKnSBTQOON7N+YWDA8cC08Fm1mU0Oo9DO2WlbLe0jZVx05CgmDMnnvx6fw8aaumSXIyLSpngn4pxiZl83szOaH/Fs3Myygc8Aj8Q0Xw18xsw+CJ9dHdqfAj4EFgB/B74D4O7rie6l82Z4XBXaAC4GbgnrLASmtrOPlNErPY1rv7AfG2vquOqJuckuR0SkTdbeEFozu72FZnf3CxJTUnKUl5d7RUVFssvosD8+8x7X/2sBt593MMfs3eI4CBGRhDGzGe5e3t5y8cyNdn7nlCSJ8N1Pj+Hp2Sv52aOzeOaHR5KX1e7vbUVE9rh4ZhAYamaPmtlqM1tlZg+b2dD21pM9o3dGOtd+cV9Wbarl8odn6VYEItIlxXPN5naiC+6DiX7H8o/QJl3EAaX9uPykvXlyViU/+r93FDgi0uXE8+PMAe4eGy53mNkPElWQ7JqLjhzNtvom/jj9fXqlp/G7MyaSltbST5FERPa8eMJmrZl9jR3Dl88C1iWuJNlV3zt2LPWNTVz3rwVkpBu/Pn0CYW5SEZGkiidsLgBuAP6b6Bf6/w5t0gX98DN7Udfo/PWFhfRKT+OKU8YrcEQk6doMmzCDwBfc/dQ9VI/sJjPjJyeOo76xiVtf/ohe6cbPTi5T4IhIUrUZNu7eaGanEZ3VSDdhZvz8s2XUNzbx95c+old6Gj86YZwCR0SSJp5utFfM7AbgAWBLc6O7z0xYVbLbzIwrT9mH+sYmbnx+IZkZafzguL2SXZaI9FDxhM1h4fmqmDYHPt355UhnSkszfnP6ROobnT//8wN6padxyTFjkl2WiPRA7V2zSQNucvcH91A90snS0oxrvrAv9Y1N/H7ae2Smp/HNI0cluywR6WHau2bTZGbfBRQ23Vh6mvHHM/ejodH5zVPz6JVunHf4yGSXJSI9SDzdaNPN7D/45DWb9a2vIl1NRnoaf/7K/tQ3NnHlP+aSnp7G1ycPT3ZZItJDxPs7G4BLYtocUF9MN9MrPY0bzj6Qi++ewX89Npst2xr49lGjk12WiPQA8cz6rP6WFJKZkcZNXzuIyx58m6unzmfDljouP2lvDYsWkYRqN2zCDdAuA0rd/SIzGwuMc/cnEl6dJERmRhp/+coB9MvO5G8vfsiGmjp++/mJZKTHMy+riEjHxdONdjswgx1DoJcB/wcobLqx9DTjqtP2oV9OJtc9+wEba+q57qwDyOqVnuzSRCQFxfNP2dHufi1QD+DuWwH1uaQAM+Oyz+zFlaeM55m5qzjv9jeorq1PdlkikoLiCZs6M+tDNCgAMxsNbEtoVbJHnXf4SP785f2pWLSBs/7+Gms36+sVkc4VT9hcATwNDDOze4BngR8ntCrZ404/YAh/P6ecBas3c+ZfX2XZhppklyQiKaTdsHH36cAZwHlE97Qpd/fnE1uWJMMxew/k7gsPYd3mbXzxpld5f1V1sksSkRQR1/Ajd1/n7k+6+xPuvjbRRUnylI8o5IFvHUqjO1/626u8tWRDsksSkRSgsa7yCWUl+Tz87cPIz+rFV295nRffX5PskkSkm2s1bMxMP+bswUr7Z/PQxYcyvH8OF9zxJn97YSFNTZ7sskSkm2rrzOYhADN7dg/VIl3MwLws7r9oMseVFfO7qfP52q2vs7KqNtlliUg3ZO4t/2vVzN4CHgO+QQt36nT3PyW2tD2rvLzcKyoqkl1Gl+TuPFixlCunzKV3rzSuPmNfTpwwKNlliUgXYGYz3L28veXaOrP5ClBLNMtAXgsP6SHMjC8fXMqT3z+C0sJsvn33DC5/+F1q6hqSXZqIdBOtntlsX8DsJHefuofqSRqd2cSnrqGJP//zfW56YSEj++fw56/sz75D+ya7LBFJks44s2n2bzP7k5lVhMcfzaygE2qUbigzI40fn7g3931zMlvrGznjxn9z0/MLadTgARFpQzxhcxtQDXwpPDYRTc4pPdjkUf15+tIjOWGfQVzz9Hy+estrrNi4NdlliUgXFe9EnFe4+4fh8Ut04zQBCrJ7ccPZB/D7L+7Lu8uqOOkvL/HUrMpklyUiXVA8YbPVzI5ofmNmhwP6J6wA0eCBM8uH8dT3P8WIohy+c89MLrqrgoVrNie7NBHpQuIZILAfcBfQfJ1mA3Cuu7+b4Nr2KA0Q2H31jU3c/OKH3PjcAmobmjh7UimXHjeWotzeyS5NRBIk3gEC7YZNzAbzAdx9027W1iUpbDrP2s3b+Ms/P+DeN5bQp1c6Fx89mgsOH0mfTN2YTSTVdHrYpDqFTedbsHoz1zw9n+lzVzEoP4v/d/xenHHgUNLTdO89kVTRmUOfRXbJmIG5/P2cch781qEUF2Txo4fe5XPXv6yJPUV6oISGjZn1NbOHzGy+mc0zs0PNrNDMppvZB+G5X1jWzOw6M1tgZu+a2YEx2zk3LP+BmZ0b036Qmc0K61xnZhbaW9yHJMekkYU89p3DuP6sA9i8rZ5zbnuDr9/6OvMqU7JHVkRa0G7YmFm6mZ1qZt83s8uaH3Fu/y/A0+6+N7AfMA+4HHjW3ccS3fXz8rDsScDY8LgIuCnsv5DobqGHAJOAK2LC46awbPN6J4b21vYhSWJmnLLfYP552VH8/LNlvLusipOve4n/emw2tfWNyS5PRBIsnjObfxDdpbM/HZgbLQwoOBK4FcDd69x9I3AacGdY7E7g9PD6NOAuj7wG9DWzEuAEYLq7r3f3DcB04MTwWb67v+rRhae7dtpWS/uQJOudkc43PjWKF390DOcdNoL/fW0xp97wMu+t1F1BRVJZRhzLDHX3fXdh26OANcDtYfj0DOBSoNjdKwHcvdLMBoblhwBLY9ZfFtraal/WQjtt7ONjzOwiojMjSktLd+EQZVcVZPfiilP24ZhxA7nswbc59YaX+cUp4zl7UimhN1REUkg8ZzZTzez4Xdh2BnAgcJO7HwBsoe3urJb+wvgutMfN3W9293J3Lx8wYEBHVpVOcuReA5h66ZFMGlnIfz46m+/cM5OqmvpklyUinSyesHkNeNTMtprZJjOrNrN4ruwuA5a5++vh/UNE4bMqdIERnlfHLD8sZv2hwIp22oe20E4b+5AuaEBeb+48fxI/PWlvps9dxcnXvUTFovXJLktEOlE8YfNH4FAg293z3T3P3fPbW8ndVwJLzWxcaDoWmAtMAZpHlJ0LPB5eTwHOCaPSJgNVoStsGnC8mfULAwOOB6aFz6rNbHIYhXbOTttqaR/SRaWlGd86ajQPXXwY6WnGl29+jeuf/UCzSYukiHimq5kGnOTuTR3euNn+wC1AJvAhcD5RwD0IlAJLgDPdfX0IjBuIRpTVAOe7e0XYzgXAz8Jmf+Put4f2cuAOoA8wFfieu7uZ9W9pH23Vqh91dh3VtfX856OzmfLOCiaPKuTPXz6AQQVZyS5LRFrQaTMImNkdRBf7pwLbmtt1W2hJJHfnoRnL+MXjc8jqlcbvv7gfx40vTnZZIrKTzpxB4COi36pkottCyx7SPJv0E98/gpKCPnzjrgp+/tgsVm+qTXZpIrILNDdaoDObrmtbQyNXT53Pnf9eREZaGl84aCjfOnIUI4pykl2aSI/Xmd1oz9HCkGJ3//Sul9f1KGy6vsXrtnDzix/yfzOW0dDYxEkTS7j4qNFMGKK7lIskS2eGzUExb7OALwAN7v7j3Suxa1HYdB+rq2u5/ZVF3P3qYqq3NXDkXgO4+KjRTB5VqB+EiuxhCb3FgJm94O5H7VJlXZTCpvvZVFvP3a8t5raXP2Lt5jr2H9aXi48ezWfKiknTbQxE9ojOPLMpjHmbBhwEXOfu41pZpVtS2HRftfWNPDRjGX97cSFL129lzMBcvn3UaE7dbzCZGbqLhkgidWbYfMSO6WEaiEanXeXuL3dGoV2Fwqb7a2hs4slZldz0/ELmr6ymOL835x02krMPKaWgT69klyeSknSnzg5S2KQOd+eF99dwy0sf8fKCteRkpvOlg4dxweEjGVaYnezyRFJKZ57ZnEl0T5pqM/s50fxmv3b3mZ1TategsElNc1ds4paXPmTKOytocuekiSV881Oj2H9Y32SXJpISOjNs3nX3fc3sCOB3wB+An7n7IZ1TategsEltlVVbuePfi7j39SVU1zYwaUQh3/jUSI7TYAKR3dKZYfOWux9gZr8DZrn7vc1tnVVsV6Cw6Rk2b2vggTeXctvLH7F841ZGFeVwwREjOf2AIeT2juf2TiISqzPD5glgOXAc0Ui0rcAb7r5fZxTaVShsepaGxiamzl7JLS99yDvLqsjMSOOIMUWcsE8xx5UV0z+3d7JLFOkWOjNssolmYp7l7h+E+8NMdPdnOqfUrkFh0zO5OzOXbOSpWZVMm7OSZRu2kmZQPqKQE/YZxPHjizWoQKQNGo3WQQobcXfmVm5i2pxVPDNnJfNXVgOwz+B8jh8/iBMmFDOuOE+zFIjEUNh0kMJGdrZo7Raembv5qo/lAAAQ40lEQVSSaXNWMXPJBtxheP9sTthnECdOGMT+Q/tqcIH0eAqbDlLYSFtWV9cyfe4qps1ZxasL11Lf6AzKz+KEfYo5cUIJB4/oR0a6ZiuQnkdh00EKG4lX1dZ6/jV/FVNnreSF99ewraGJwpxMjh9fzAkTBnH46CJNkyM9hsKmgxQ2sitq6hp44b01TJ29kn/NX83mbQ3kZWVw7N4DOXFCCUftNYA+menJLlMkYRQ2HaSwkd21raGRVxas5enZK5k+dxUbaurJzEhjwuB8Diztx4HD+3FgaT8GFWQlu1SRTqOw6SCFjXSmhsYm3vhoPc+9t5qZSzYya3kVdQ1NAAwuyOKAEDwHlvZln8EF6naTbivesNFPpkUSICM9jcPGFHHYmCIgOuuZu2ITM5dsZOaSDby1eANPvlsJQGZGGhOHFHDQ8H4cOXYAk0YWKnwk5ejMJtCZjexpK6tqmblkAzMXb2Dmkg3MXr6JusYmcntncOReRXx672KOGTdAsxlIl6ZutA5S2Eiyba2Lrvk8O38Vz85bzerqbZjBAcP6cmxZMceWDdSPSqXLUdh0kMJGuhJ3Z/byTTw7fxX/mr+ad5dVATCkbx+OLRvIsWXFHDKykKxeGukmyaWw6SCFjXRlqzbV8q/5q3l23mpeXrCG2vomMtPT2HdoAQePLGTSyEIOGt6P/CzdkVT2LIVNBylspLuorW/k1YXreO3DdbyxaD2zllXR0OSkGew9KJ9JIXwOHlHIgDxd75HEUth0kMJGuquaugbeXrKRNxat542P1vPWko1srW8EYGRRDpNGRGc9E4YUMLY4l16aVkc6kYY+i/QQ2ZkZHxtmXd/YxOzlVbwZwufpOSt5oGIpEA2zLivJZ8LgfCYOKWDCkAL2Ks7TUGtJOJ3ZBDqzkVTV1OR8tG4Ls5dXMXt5FbOWVzFn+SaqtzUAkJmexrhBeUwYks+EIQVMDAGkwQcSD3WjdZDCRnqSpiZnyfoaZi2vYvaKqhBEm6jaWg9ARpqxV/GOAJowpICyQfma500+QWHTQQob6encnWUbtkYBFM6AZi+vYkNNFEBpBmMH5rHPkHwmDC5g4tACxpfkk9NbvfE9ma7ZiEiHmBnDCrMZVpjNyRNLgCiAVlTVbu+Cm728ihffX8sjM5eHdWBE/xz2HpTH3oPyKSvJo6wkn6H9+ujHp/IxChsRaZWZMaRvH4b07cMJ+wza3r5qU+32s5/5ldXMq9zE1Nkrt3+e2zsjCqCS5hDKZ9ygPHJ1FtRj6ZsXkQ4rzs+iOD+LY8uKt7dt2dbAe6uqmV9ZzfyVm5hfWc3jb6/g7tol25cZ0rcPw/tnM6IohxH9sxnRP4cRRTmUFmZrQEKKU9iISKfI6Z0RbpvQb3ubu7N849btZz8frt3CR2u3MHVW5fZrQRB1x5XkZzGiKIfh/XMYWZTNyKJcxhXnMbRfH9LS1CXX3SU0bMxsEVANNAIN7l5uZoXAA8AIYBHwJXffYFEH71+Ak4Ea4Dx3nxm2cy7w87DZX7v7naH9IOAOoA/wFHCpu3tr+0jksYrIJ5kZQ/tlM7RfNseNL/7YZ1U19SxatyV6rK1h8botfLRuC9PmrGT9lrrty2VnpjO2OI9xxbnsVRx1y+01KJcBub11XagbSehotBA25e6+NqbtWmC9u19tZpcD/dz9J2Z2MvA9orA5BPiLux8SgqMCKAccmAEcFALqDeBS4DWisLnO3ae2to+2atVoNJGuo2prPQvXbOaDVdXMX1nN+6uqeW9lNWs37wihwpxM9iqOzn7GDcpnzMBcxgzMpTAnM4mV9zxdeTTaacDR4fWdwPPAT0L7XR6l32tm1tfMSsKy0919PYCZTQdONLPngXx3fzW03wWcDkxtYx8i0g0U9On1iS45gLWbt20Pnubnh2cuZ/O2xduXKczJZMyAXEYPzGVsCKAxA3MpKcjSmVASJTpsHHjGzBz4m7vfDBS7eyWAu1ea2cCw7BBgacy6y0JbW+3LWminjX2ISDdWlNubotzeHDa6aHtb83WhBas3f+wxdXYl98VcF8rJTGf0wFzGDMhl3KBoiHZZSb4mK91DEh02h7v7ivDHfrqZzW9j2Zb+yeG70B43M7sIuAigtLS0I6uKSBcRe13o6HE7/l3p7qzbUveJEHpl4VoeeWv59uUG5PUOwZPH+JJ8xpfkM7IohwxNWNqpEho27r4iPK82s0eBScAqMysJZxwlwOqw+DJgWMzqQ4EVof3ondqfD+1DW1ieNvaxc303AzdDdM1mV49TRLoeM9t+JjR5VP+PfbZhSx3zKjcxt3IT88JIudsWrqW+Mfoz0Dsjjb2K8ygryWP0gFwGFWQxMC+L4vzeDCrIIjtTA3k7KmH/i5lZDpDm7tXh9fHAVcAU4Fzg6vD8eFhlCvBdM7ufaIBAVQiLacBvzay58/Z44Kfuvt7Mqs1sMvA6cA5wfcy2WtqHiAj9cjI/NlM2QF1DEwvXbGZe5abwqObZeat5sGLZJ9bP653BwPze239vFD16Myg/K5qFoV82Bdm6kV2sRMZzMfBouCCXAdzr7k+b2ZvAg2Z2IbAEODMs/xTRSLQFREOfzwcIofIr4M2w3FXNgwWAi9kx9HlqeEAUMi3tQ0SkRc23Xygryf9Y++ZtDaysqmX1plpWVdeyatM2Vm2qDY9tvLloPas3baOuselj6+VnZTCsMJvSMAVQFEJ9GFaYzdB+feid0bN+xKqJOAMNfRaRXeXubKypZ0XVVpau38rS9TUs3VDDkvU14fVW6hp2hJEZFOdlMbhvFiVhOqCSgixKCsLrvln0z8nsFqPnuvLQZxGRlGJm9MvJpF9OJvsMLvjE501NzprN23aEz/qtLFlfQ2XVVuYsr2L63FUfCyOIzrQGhwAq6ZvF4II+DCrIYlB+FoMKsigpyKKwmwQSKGxERBIuLc22X9s5eEThJz53d9ZvqWPFxlpWVG2lcuNWVlTVsmLjViqranl14TpWV2+jsenjPVGZ6WkUF/SmJD8EUQijwX37UFqYzfD+2V3mFhBdowoRkR7MzOif25v+ub2ZOPSTZ0YAjU3O2s3bqKyqZWXVVlZW1VK5qTZ6rqrlnWUbeXpO7SfOkIpyMxlWmM3wcP2otH/O9iAamLfnpvxR2IiIdAPpMWdHDOvb4jLuzoaaepZviLrpFq/fwpJ10bWjNxdtYMo7K4g9Ocrqlcawftn89esHMXpAbkLrV9iIiKQIM6MwJ5PCnMwWz5DqGppYvnEri9dtYen6Ghavq2Hx+hr6ZSd+PjmFjYhID5GZkcbIohxGFuXs8X1rPgYREUk4hY2IiCScwkZERBJOYSMiIgmnsBERkYRT2IiISMIpbEREJOEUNiIiknC6xUBgZmuAxcmuYzcVAWuTXUQCpfrxQeofo46v+9v5GIe7+4D2VlLYpBAzq4jnvhLdVaofH6T+Mer4ur9dPUZ1o4mISMIpbEREJOEUNqnl5mQXkGCpfnyQ+seo4+v+dukYdc1GREQSTmc2IiKScAobERFJOIVNCjCzRWY2y8zeNrOKZNfTGczsNjNbbWazY9oKzWy6mX0Qnvsls8bd0crxXWlmy8P3+LaZnZzMGneHmQ0zs+fMbJ6ZzTGzS0N7Kn2HrR1jSnyPZpZlZm+Y2Tvh+H4Z2kea2evhO3zAzOK6zaeu2aQAM1sElLt7yvyYzMyOBDYDd7n7hNB2LbDe3a82s8uBfu7+k2TWuataOb4rgc3u/odk1tYZzKwEKHH3mWaWB8wATgfOI3W+w9aO8UukwPdoZgbkuPtmM+sFvAxcClwGPOLu95vZX4F33P2m9ranMxvpktz9RWD9Ts2nAXeG13cS/YfdLbVyfCnD3SvdfWZ4XQ3MA4aQWt9ha8eYEjyyObztFR4OfBp4KLTH/R0qbFKDA8+Y2QwzuyjZxSRQsbtXQvQfOjAwyfUkwnfN7N3QzdZtu5himdkI4ADgdVL0O9zpGCFFvkczSzezt4HVwHRgIbDR3RvCIsuIM2AVNqnhcHc/EDgJuCR00Uj3cxMwGtgfqAT+mNxydp+Z5QIPAz9w903JricRWjjGlPke3b3R3fcHhgKTgLKWFotnWwqbFODuK8LzauBRov9TpKJVoZ+8ub98dZLr6VTuvir8x90E/J1u/j2Gfv6HgXvc/ZHQnFLfYUvHmGrfI4C7bwSeByYDfc0sI3w0FFgRzzYUNt2cmeWEi5OYWQ5wPDC77bW6rSnAueH1ucDjSayl0zX/EQ4+Tzf+HsPF5VuBee7+p5iPUuY7bO0YU+V7NLMBZtY3vO4DHEd0Xeo54Ithsbi/Q41G6+bMbBTR2QxABnCvu/8miSV1CjO7DziaaDrzVcAVwGPAg0ApsAQ409275UX2Vo7vaKKuFwcWAd9qvr7R3ZjZEcBLwCygKTT/jOiaRqp8h60d41mkwPdoZvsSDQBIJzoxedDdrwp/c+4HCoG3gK+5+7Z2t6ewERGRRFM3moiIJJzCRkREEk5hIyIiCaewERGRhFPYiIhIwilsJKWY2YjYmZSTyczuMLMvtr/kbu/nzDDz8HOJrCv8b3t2xysUUdiIdElmlt6BxS8EvuPuxySqnmAE0KGw6eBxSApT2EjKMrNRZvaWmR3cznKbzew34b4dr5lZcWj/2BmAmW0Oz0eb2Qtm9qCZvW9mV5vZV8O9P2aZ2eiYzR9nZi+F5T4X1k83s9+b2ZthssZvxWz3OTO7l+iHgjvXeVbY/mwzuya0/QI4Avirmf2+hXV+HNZ5x8yubuHzRWZWFF6Xm9nz4fVRtuN+LG+FWSquBj4V2n4Y73GEWS6eDDXMNrMvt/V9SGrKaH8Rke7HzMYR/cr5fHd/28wGA7e4e0s3ssoBXnP3/7TonjnfBH7dzi72I5qUcD3wYdj2JItuoPU94AdhuRHAUUQTMz5nZmOAc4Aqdz/YzHoDr5jZM2H5ScAEd/9op+MZDFwDHARsIJrl+/Twi+5PA//h7hU7rXMS0fTvh7h7jZkVtnNMsf4DuMTdXwkTTdYCl4f9NIfmRfEch5l9AVjh7p8N6xV0oA5JETqzkVQ0gGi+pq+5+9sQTVbaStAA1AFPhNcziAKiPW+G+5lsI5p2vfmP7Kyd1n/Q3Zvc/QOiUNqbaP66c8LU7a8D/YGxYfk3dg6a4GDgeXdfE6Z3vwdob3bv44Db3b0GoIPTwrwC/MnMvg/0jZlSPla8xzGL6AzvGjP7lLtXdaAOSREKG0lFVcBS4PA4l6/3HfM2NbLjjL+B8N9ImHQx9va3sXNBNcW8b+LjPQY7zwflgAHfc/f9w2OkuzeH1ZZWarQ4j2Xnddqbj2r7MQJZ24t0vxr4BtAHeM3M9m5l++0eh7u/T3RGNgv4Xej6kx5GYSOpqI6o++ic3Rw9tYjojyREd5jstQvbONPM0sJ1nFHAe8A04GKLpqfHzPYKM3a35XXgKDMrChfdzwJeaGedZ4ALzCw77KelbrRF7DjGLzQ3mtlod5/l7tcAFURnZNVAXsy6cR1H6AKscfe7gT8AB7ZTt6QgXbORlOTuW8IF+elmtgV4k9av2bTm78DjZvYG8Cytn3W05T2iUCgGvu3utWZ2C1FX28xwxrSGdm6t6+6VZvZToundDXjK3duc2t3dnzaz/YEKM6sDniKalTjWL4Fbzax5RuZmPzCzY4jO9OYCU4nO2hrM7B3gDuAvcR7HROD3ZtYE1AMXt1W3pCbN+iwiIgmnbjQREUk4hY2IiCScwkZERBJOYSMiIgmnsBERkYRT2IiISMIpbEREJOH+P0k+vZA4gWRlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f285ba748>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg = []\n",
    "for k in range(2, 30):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(c_scaled)\n",
    "    avg.append(kmeans.inertia_)\n",
    "    \n",
    "plt.plot(range(2,30), avg)\n",
    "plt.title('Choosing k')\n",
    "plt.xlabel('k: number of clusters')\n",
    "plt.ylabel('sum of errors per cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a good option for the number of clusters (k) have been found, it is time to create a function that given a dataset an k performs k-means clustering. After this, differences between the representative columns ONLINE_PURCHASE, PRODUCT_GROUP and CUSTOMER_GROUP are found. This is done creating a dataframe where each row is a cluster and the columns are the % of each of the clases of the previous columns. Finally, it can be observed that by ordering the last column the other columns are in crescent order too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(customers['ONLINE_PURCHASE']) # [0, 1]\n",
    "# np.unique(customers['PRODUCT_GROUP']) # ['COSMETIC', 'COSMETIC_AND_FOOD', 'FOOD']\n",
    "# np.unique(customers['CUSTOMER_GROUP']) # ['MULTI_BUYER', 'SINGLE_BUYER']\n",
    "\n",
    "def k_means(df_scaled, k):\n",
    "    \"\"\"\n",
    "    Perform k-means clustering\n",
    "    \n",
    "    Input: \n",
    "        df_scaled: dataframe without categorical features and standardize \n",
    "        k: number of clusters\n",
    "        \n",
    "    Output:\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(df_scaled)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    return kmeans, labels\n",
    "\n",
    "k = 5\n",
    "kmeans, labels = k_means(c_scaled, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py:312: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 191652 but corresponding boolean dimension is 185560\n",
      "  return self.values[slicer]\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py:2095: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 191652 but corresponding boolean dimension is 185560\n",
      "  result = getitem(key)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_1</th>\n",
       "      <th>op_0</th>\n",
       "      <th>pg_cosmetic</th>\n",
       "      <th>pg_cosmetic_food</th>\n",
       "      <th>pg_food</th>\n",
       "      <th>cg_multibuyer</th>\n",
       "      <th>cg_singlebuyer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.33</td>\n",
       "      <td>97.67</td>\n",
       "      <td>5.79</td>\n",
       "      <td>13.29</td>\n",
       "      <td>80.92</td>\n",
       "      <td>17.50</td>\n",
       "      <td>82.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.93</td>\n",
       "      <td>98.07</td>\n",
       "      <td>4.86</td>\n",
       "      <td>11.34</td>\n",
       "      <td>83.80</td>\n",
       "      <td>14.80</td>\n",
       "      <td>85.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.40</td>\n",
       "      <td>98.60</td>\n",
       "      <td>3.56</td>\n",
       "      <td>8.42</td>\n",
       "      <td>88.02</td>\n",
       "      <td>11.01</td>\n",
       "      <td>88.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.40</td>\n",
       "      <td>97.60</td>\n",
       "      <td>5.98</td>\n",
       "      <td>13.90</td>\n",
       "      <td>80.12</td>\n",
       "      <td>18.25</td>\n",
       "      <td>81.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.96</td>\n",
       "      <td>99.04</td>\n",
       "      <td>2.45</td>\n",
       "      <td>5.71</td>\n",
       "      <td>91.84</td>\n",
       "      <td>7.51</td>\n",
       "      <td>92.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   op_1   op_0  pg_cosmetic  pg_cosmetic_food  pg_food  cg_multibuyer  \\\n",
       "0  2.33  97.67         5.79             13.29    80.92          17.50   \n",
       "1  1.93  98.07         4.86             11.34    83.80          14.80   \n",
       "2  1.40  98.60         3.56              8.42    88.02          11.01   \n",
       "3  2.40  97.60         5.98             13.90    80.12          18.25   \n",
       "4  0.96  99.04         2.45              5.71    91.84           7.51   \n",
       "\n",
       "   cg_singlebuyer  \n",
       "0           82.50  \n",
       "1           85.20  \n",
       "2           88.99  \n",
       "3           81.75  \n",
       "4           92.49  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_records = c_scaled.shape[0]\n",
    "values = []\n",
    "for cluster in range(k):\n",
    "    index = labels == cluster\n",
    "    op_1 = round(np.sum(customers['ONLINE_PURCHASE'][index]) / n_records * 100, 2)\n",
    "    op_0 = 100 - op_1\n",
    "    \n",
    "    pg_cosmetic = round(np.sum(customers['PRODUCT_GROUP'][index] == 'COSMETIC') / n_records * 100, 2)\n",
    "    pg_cosmetic_food = round(np.sum(customers['PRODUCT_GROUP'][index] == 'COSMETIC_AND_FOOD') / n_records * 100, 2)\n",
    "    pg_food = 100 - pg_cosmetic - pg_cosmetic_food\n",
    "    \n",
    "    cg_multibuyer = round(np.sum(customers['CUSTOMER_GROUP'][index] == 'MULTI_BUYER') / n_records * 100, 2)\n",
    "    cg_singlebuyer = 100 - cg_multibuyer\n",
    "    \n",
    "    aux = [op_1, op_0, pg_cosmetic, pg_cosmetic_food, pg_food, cg_multibuyer, cg_singlebuyer]\n",
    "    values.append(aux)\n",
    "    \n",
    "cols = ['op_1', 'op_0', 'pg_cosmetic', 'pg_cosmetic_food', 'pg_food', 'cg_multibuyer', 'cg_singlebuyer']\n",
    "df = pd.DataFrame(values, index = range(k), columns = cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_1</th>\n",
       "      <th>op_0</th>\n",
       "      <th>pg_cosmetic</th>\n",
       "      <th>pg_cosmetic_food</th>\n",
       "      <th>pg_food</th>\n",
       "      <th>cg_multibuyer</th>\n",
       "      <th>cg_singlebuyer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.40</td>\n",
       "      <td>97.60</td>\n",
       "      <td>5.98</td>\n",
       "      <td>13.90</td>\n",
       "      <td>80.12</td>\n",
       "      <td>18.25</td>\n",
       "      <td>81.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.33</td>\n",
       "      <td>97.67</td>\n",
       "      <td>5.79</td>\n",
       "      <td>13.29</td>\n",
       "      <td>80.92</td>\n",
       "      <td>17.50</td>\n",
       "      <td>82.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.93</td>\n",
       "      <td>98.07</td>\n",
       "      <td>4.86</td>\n",
       "      <td>11.34</td>\n",
       "      <td>83.80</td>\n",
       "      <td>14.80</td>\n",
       "      <td>85.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.40</td>\n",
       "      <td>98.60</td>\n",
       "      <td>3.56</td>\n",
       "      <td>8.42</td>\n",
       "      <td>88.02</td>\n",
       "      <td>11.01</td>\n",
       "      <td>88.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.96</td>\n",
       "      <td>99.04</td>\n",
       "      <td>2.45</td>\n",
       "      <td>5.71</td>\n",
       "      <td>91.84</td>\n",
       "      <td>7.51</td>\n",
       "      <td>92.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   op_1   op_0  pg_cosmetic  pg_cosmetic_food  pg_food  cg_multibuyer  \\\n",
       "3  2.40  97.60         5.98             13.90    80.12          18.25   \n",
       "0  2.33  97.67         5.79             13.29    80.92          17.50   \n",
       "1  1.93  98.07         4.86             11.34    83.80          14.80   \n",
       "2  1.40  98.60         3.56              8.42    88.02          11.01   \n",
       "4  0.96  99.04         2.45              5.71    91.84           7.51   \n",
       "\n",
       "   cg_singlebuyer  \n",
       "3           81.75  \n",
       "0           82.50  \n",
       "1           85.20  \n",
       "2           88.99  \n",
       "4           92.49  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('cg_singlebuyer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish the part of unsupervised learning, the dataset azdias must be used. This dataset is very useful to find citizens of germany that would be good targets of a marketing campaign. That is, those citizens that are closer to the cluster center number 3 (the cluster with highest online purchase percentage). We can find the closest one with the method transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Treating NA in pandas dataframe ---\n",
      "Shape of dataframe after NA treatment:  (891221, 113)\n",
      "Shape of dataframe before NA treatment:  (868119, 113)\n",
      "\n",
      "Number of features removed:  0\n",
      "Percentage of records removed:  2.59 %\n",
      "--- Creating dummies and standardizing ---\n",
      "Number of dummies variables created:  0\n",
      "Number of scaled features:  113\n"
     ]
    }
   ],
   "source": [
    "a = azdias[c_scaled.columns]\n",
    "a_nas = treat_NA(a, 100)\n",
    "a_dummies, a_scaled = dummies_and_scale(a_nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_closer = np.transpose(kmeans.transform(a_scaled))\n",
    "aux = dict(enumerate(abs(a_closer[3])))\n",
    "aux_sort = {k: v for k, v in sorted(aux.items(), key=lambda item: item[1])}    \n",
    "campaign_target_citizens_index = list(aux_sort.keys())[-3000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "mailout_train = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the train dataset is imbalanced in the response variable, a little exploratory analysis is done in each of the clusters:\n",
    "    - percentage of 1's per cluster\n",
    "    - distribution of 1's per cluster\n",
    "    - percentage of records per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Treating NA in pandas dataframe ---\n",
      "Shape of dataframe after NA treatment:  (42962, 114)\n",
      "Shape of dataframe before NA treatment:  (41671, 114)\n",
      "\n",
      "Number of features removed:  0\n",
      "Percentage of records removed:  3.0 %\n",
      "--- Creating dummies and standardizing ---\n",
      "Number of dummies variables created:  0\n",
      "Number of scaled features:  114\n"
     ]
    }
   ],
   "source": [
    "cols = c_scaled.columns.tolist() ; cols.append('RESPONSE')\n",
    "train_descriptive = mailout_train[cols]\n",
    "train_descriptive_nas = treat_NA(train_descriptive, 100)\n",
    "train_descriptive_dummies, train_descriptive_scaled = dummies_and_scale(train_descriptive_nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.18 16.18 17.09\n",
      "1 1.27 16.57 16.29\n",
      "2 1.32 35.07 33.04\n",
      "3 1.44 24.47 21.12\n",
      "4 0.77 7.71 12.46\n"
     ]
    }
   ],
   "source": [
    "train_clusters = kmeans.predict(train_descriptive_scaled.drop('RESPONSE', axis=1))\n",
    "n_responses = np.sum(train_descriptive_scaled['RESPONSE'] == 1)\n",
    "for cluster in range(k):\n",
    "    index = train_clusters == cluster\n",
    "    por_resp_cluster = round(np.sum(train_descriptive_scaled['RESPONSE'][index]) / np.sum(index) * 100, 2) # % of 1's per cluster\n",
    "    por_re_c = round(np.sum(train_descriptive_scaled['RESPONSE'][index]) / n_responses * 100, 2) # % Distribution of 1's per cluster\n",
    "    por_1_cluster = round(np.sum(index) / train_clusters.shape[0] * 100, 2) # % of records in each cluster\n",
    "    \n",
    "    if cluster == 4:\n",
    "        train_cluster = train_descriptive_scaled.iloc[index,:]\n",
    "    print(cluster, por_resp_cluster, por_re_c, por_1_cluster)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three different training datasets are considered:\n",
    "    - The mailout_train dataset preprocessed (train_scaled)\n",
    "    - The mailout_train clusterized (train_cluster)\n",
    "    - The mailout_train balanced (train_scaled_balanced)\n",
    "    \n",
    "After this, stratified subsets for training, validation and testing are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Treating NA in pandas dataframe ---\n",
      "Shape of dataframe after NA treatment:  (42962, 16)\n",
      "Shape of dataframe before NA treatment:  (42357, 16)\n",
      "\n",
      "Number of features removed:  0\n",
      "Percentage of records removed:  1.41 %\n",
      "--- Creating dummies and standardizing ---\n",
      "Number of dummies variables created:  0\n",
      "Number of scaled features:  16\n"
     ]
    }
   ],
   "source": [
    "train_cols = selected_cols\n",
    "train_cols.append('RESPONSE')\n",
    "train = mailout_train[train_cols]\n",
    "train_nas = treat_NA(train, 100)\n",
    "train_dummies, train_scaled = dummies_and_scale(train_nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old percentage of 1s is: 1.24418632103 %\n",
      "New percentage of 1s is: 18.5498064062 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train_scaled_remove_0 = train_scaled.iloc[:40000,:]\n",
    "index = train_scaled_remove_0[train_scaled_remove_0['RESPONSE'] == 0].index\n",
    "train_scaled_remove_0.drop(index, axis=0, inplace=True)\n",
    "\n",
    "train_scaled_balanced = pd.concat([train_scaled_remove_0, train_scaled.iloc[40000:,:]], axis=0)\n",
    "balanced_1 = np.sum(train_scaled_balanced['RESPONSE']  == 1) / train_scaled_balanced.shape[0] * 100\n",
    "print('Old percentage of 1s is:', train_scaled['RESPONSE'].sum() / train_scaled.shape[0] * 100 , '%')\n",
    "print('New percentage of 1s is:', balanced_1, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train_total = train_cluster[train_cols] \n",
    "train_total = train_scaled \n",
    "#train_total = train_scaled_balanced\n",
    "\n",
    "y = train_total['RESPONSE']\n",
    "X = train_total.drop('RESPONSE', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next three cells define the neccesary parts of a neural network:\n",
    "    - Data loaders for training, validation and testing\n",
    "    - Class defining the net configuration\n",
    "    - Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "\n",
    "train_target = torch.tensor(y_train.values.astype(np.float32))\n",
    "train = torch.tensor(X_train.values.astype(np.float32)) \n",
    "train_tensor = torch.utils.data.TensorDataset(train, train_target) \n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = batch_size, \\\n",
    "                                           num_workers=num_workers, shuffle=True)\n",
    "\n",
    "valid_target = torch.tensor(y_valid.values.astype(np.float32))\n",
    "valid = torch.tensor(X_valid.values.astype(np.float32)) \n",
    "valid_tensor = torch.utils.data.TensorDataset(valid, valid_target) \n",
    "valid_loader = torch.utils.data.DataLoader(dataset = valid_tensor, batch_size = batch_size, \\\n",
    "                                           num_workers=num_workers, shuffle=True)\n",
    "\n",
    "test_target = torch.tensor(y_test.values.astype(np.float32))\n",
    "test = torch.tensor(X_test.values.astype(np.float32)) \n",
    "test_tensor = torch.utils.data.TensorDataset(test, test_target) \n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_tensor, batch_size = batch_size, \\\n",
    "                                           num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Define a neural network that performs binary classification.\n",
    "    The network accept  number of features as input, and produce \n",
    "    a single sigmoid value, that can be rounded to a label: 0 or 1, as output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_features, hidden_dim1, hidden_dim2, hidden_dim3, output_dim):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up linear layers.\n",
    "        Use the input parameters to help define the layers of your model.\n",
    "        :param input_features: the number of input features in your training/test data\n",
    "        :param hidden_dim: helps define the number of nodes in the hidden layer(s)\n",
    "        :param output_dim: the number of outputs you want to produce\n",
    "        \"\"\"\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        # define any initial layers\n",
    "        self.fc1 = nn.Linear(input_features, hidden_dim1)\n",
    "        self.fc11 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc12 = nn.Linear(hidden_dim2, hidden_dim3)\n",
    "        self.fc2 = nn.Linear(hidden_dim3, output_dim)\n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    \n",
    "    ## TODO: Define the feedforward behavior of the network\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on input features, x.\n",
    "        :param x: A batch of input features of size (batch_size, input_features)\n",
    "        :return: A single, sigmoid-activated value as output\n",
    "        \"\"\"\n",
    "        \n",
    "        # define the feedforward behavior\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc11(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc12(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 2nd hidden layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return torch.sigmoid(x) # apply sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_(n_epochs, loaders, model, optimizer, criterion, use_cuda):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    train_l, valid_l = [], []\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            #train_loss += loss.data*data.size(0)\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss \n",
    "            #valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        train_l.append(train_loss) ; valid_l.append(valid_loss)\n",
    "        \n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            valid_loss_min = valid_loss   \n",
    "            \n",
    "    # return trained model\n",
    "    return model, train_l, valid_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell trains the model for a given number of epochs, learning rate and net configuration. If GPU power is available it will be used. Because this is a binary classification the binary cross entropy loss is considered (BCELoss). A plot of the training and validation loss along the epochs is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1474: UserWarning: Using a target size (torch.Size([17])) that is different to the input size (torch.Size([17, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.099070 \tValidation Loss: 0.067112\n",
      "Validation loss decreased (inf --> 0.067112).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.069595 \tValidation Loss: 0.066353\n",
      "Validation loss decreased (0.067112 --> 0.066353).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.068309 \tValidation Loss: 0.065549\n",
      "Validation loss decreased (0.066353 --> 0.065549).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.067983 \tValidation Loss: 0.065607\n",
      "Epoch: 5 \tTraining Loss: 0.067648 \tValidation Loss: 0.065275\n",
      "Validation loss decreased (0.065549 --> 0.065275).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.067054 \tValidation Loss: 0.065228\n",
      "Validation loss decreased (0.065275 --> 0.065228).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.067846 \tValidation Loss: 0.065198\n",
      "Validation loss decreased (0.065228 --> 0.065198).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.067969 \tValidation Loss: 0.066130\n",
      "Epoch: 9 \tTraining Loss: 0.066949 \tValidation Loss: 0.065252\n",
      "Epoch: 10 \tTraining Loss: 0.066755 \tValidation Loss: 0.064962\n",
      "Validation loss decreased (0.065198 --> 0.064962).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.066813 \tValidation Loss: 0.065092\n",
      "Epoch: 12 \tTraining Loss: 0.066811 \tValidation Loss: 0.067370\n",
      "Epoch: 13 \tTraining Loss: 0.066735 \tValidation Loss: 0.067006\n",
      "Epoch: 14 \tTraining Loss: 0.066696 \tValidation Loss: 0.065017\n",
      "Epoch: 15 \tTraining Loss: 0.066554 \tValidation Loss: 0.065915\n",
      "Epoch: 16 \tTraining Loss: 0.066417 \tValidation Loss: 0.065491\n",
      "Epoch: 17 \tTraining Loss: 0.066779 \tValidation Loss: 0.065878\n",
      "Epoch: 18 \tTraining Loss: 0.066792 \tValidation Loss: 0.065771\n",
      "Epoch: 19 \tTraining Loss: 0.066171 \tValidation Loss: 0.066863\n",
      "Epoch: 20 \tTraining Loss: 0.067029 \tValidation Loss: 0.066814\n",
      "Epoch: 21 \tTraining Loss: 0.066197 \tValidation Loss: 0.067176\n",
      "Epoch: 22 \tTraining Loss: 0.066387 \tValidation Loss: 0.064862\n",
      "Validation loss decreased (0.064962 --> 0.064862).  Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 0.066273 \tValidation Loss: 0.065015\n",
      "Epoch: 24 \tTraining Loss: 0.065971 \tValidation Loss: 0.067947\n",
      "Epoch: 25 \tTraining Loss: 0.066153 \tValidation Loss: 0.065209\n",
      "Epoch: 26 \tTraining Loss: 0.066111 \tValidation Loss: 0.066261\n",
      "Epoch: 27 \tTraining Loss: 0.065949 \tValidation Loss: 0.065662\n",
      "Epoch: 28 \tTraining Loss: 0.065610 \tValidation Loss: 0.065989\n",
      "Epoch: 29 \tTraining Loss: 0.065894 \tValidation Loss: 0.067166\n",
      "Epoch: 30 \tTraining Loss: 0.065464 \tValidation Loss: 0.066082\n",
      "Epoch: 31 \tTraining Loss: 0.065701 \tValidation Loss: 0.064898\n",
      "Epoch: 32 \tTraining Loss: 0.066120 \tValidation Loss: 0.066021\n",
      "Epoch: 33 \tTraining Loss: 0.065648 \tValidation Loss: 0.067346\n",
      "Epoch: 34 \tTraining Loss: 0.065951 \tValidation Loss: 0.065469\n",
      "Epoch: 35 \tTraining Loss: 0.066192 \tValidation Loss: 0.067889\n",
      "Epoch: 36 \tTraining Loss: 0.065569 \tValidation Loss: 0.066371\n",
      "Epoch: 37 \tTraining Loss: 0.065330 \tValidation Loss: 0.065216\n",
      "Epoch: 38 \tTraining Loss: 0.065011 \tValidation Loss: 0.067132\n",
      "Epoch: 39 \tTraining Loss: 0.065293 \tValidation Loss: 0.066163\n",
      "Epoch: 40 \tTraining Loss: 0.065569 \tValidation Loss: 0.065314\n",
      "Epoch: 41 \tTraining Loss: 0.065856 \tValidation Loss: 0.068791\n",
      "Epoch: 42 \tTraining Loss: 0.065290 \tValidation Loss: 0.071378\n",
      "Epoch: 43 \tTraining Loss: 0.065097 \tValidation Loss: 0.071677\n",
      "Epoch: 44 \tTraining Loss: 0.065933 \tValidation Loss: 0.068197\n",
      "Epoch: 45 \tTraining Loss: 0.065132 \tValidation Loss: 0.065415\n",
      "Epoch: 46 \tTraining Loss: 0.065196 \tValidation Loss: 0.067287\n",
      "Epoch: 47 \tTraining Loss: 0.065645 \tValidation Loss: 0.068252\n",
      "Epoch: 48 \tTraining Loss: 0.064960 \tValidation Loss: 0.070409\n",
      "Epoch: 49 \tTraining Loss: 0.065012 \tValidation Loss: 0.067260\n",
      "Epoch: 50 \tTraining Loss: 0.065017 \tValidation Loss: 0.065252\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc05c5909e8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "loaders = {}\n",
    "loaders['train'] = train_loader\n",
    "loaders['valid'] = valid_loader\n",
    "model = BinaryClassifier(15, 300, 50, 300, 1)\n",
    "#model = BinaryClassifier(14, 300, 1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "epochs = 50\n",
    "model_scratch, train_l, valid_l = train_(epochs, loaders, model, optimizer, criterion, use_cuda)\n",
    "\n",
    "plt.plot(range(1,epochs+1), train_l)\n",
    "plt.plot(range(1,epochs+1), valid_l)\n",
    "plt.xlabel('Number of epoch')\n",
    "plt.legend(['Train loss', 'Validation loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell performs the area under the curve (AUC) metric for the model trained in the test dataset. The closest this metric is to 1 the best the model trained is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC metric of the neural network is:  0.685370531624\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y = test_target.detach().numpy()\n",
    "pred = model_scratch(test).detach().numpy() \n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print('AUC metric of the neural network is: ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark model is trained and tested in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC metric of the logistic regression is:  0.5\n"
     ]
    }
   ],
   "source": [
    "y = train_target.detach().numpy()\n",
    "X = train.detach().numpy()\n",
    "c_clf, c_coefs = logit_reg(y, X)\n",
    "\n",
    "y = test_target.detach().numpy()\n",
    "pred = c_clf.predict(test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print('AUC metric of the logistic regression is: ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer  this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "mailout_test = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Treating NA in pandas dataframe ---\n",
      "Shape of dataframe after NA treatment:  (42833, 14)\n",
      "Shape of dataframe before NA treatment:  (42255, 14)\n",
      "\n",
      "Number of features removed:  0\n",
      "Percentage of records removed:  1.35 %\n",
      "--- Creating dummies and standardizing ---\n",
      "Number of dummies variables created:  0\n",
      "Number of scaled features:  14\n"
     ]
    }
   ],
   "source": [
    "test_k = mailout_test[selected_cols]\n",
    "test_k_nas = treat_NA(test_k, 100)\n",
    "test_k_dummies, test_k_scaled = dummies_and_scale(test_k_nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle = pd.DataFrame(mailout_test['LNR'][test_k_scaled.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_k_scaled_t = torch.tensor(test_k_scaled.values.astype(np.float32)) \n",
    "responses = model_scratch(test_k_scaled_t).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle['RESPONSE'] = responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle.to_csv('kaggle_test_responses.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LNR', 'RESPONSES'], dtype='object')"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
